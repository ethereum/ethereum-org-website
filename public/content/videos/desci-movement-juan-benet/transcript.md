# The DeSci Movement with Juan Benet

A seminar presentation by **Juan Benet**, founder of Protocol Labs and inventor of IPFS and Filecoin, on how the decentralized science (DeSci) movement can transform scientific research over the next decade. Recorded as part of the Future of Science Seminar series hosted by the DeSci Foundation.

**Host:** Welcome to the Future of Science Seminar. This time we're joined by Juan Benet, founder of Protocol Labs and the inventor of IPFS and Filecoin. In this seminar, we talk about Juan's visions for the next thirty years in science and technology — including how we can close the gap between scientific research and technological innovation, translating new knowledge into new technologies. We also talk about research funding, how we can increase it, and how we can make sure it's spent more efficiently. And we talk about open source software development and how it's a lot like open science — with the exception that open source software is really a thing in software development, while open science is kind of a niche. We explore why that is and what we can do to change that, so make sure you stick around for that part as well.

## Science as the Engine of Progress {0:59}

**Juan Benet:** What I'm going to do today is focus on DeSci — the DeSci-oriented changes and the opportunities it has to improve science over the next two to five years. The technology changes happening now can put in place a better trajectory for the next five to fifteen years. There are other technological improvements to science that are going to be transcendental — things like all of the machine-learning-based discovery — but I'm going to separate that out into a future conversation.

Today I want to discuss several points. First, science is the engine of progress and why it's key to everything we're doing. Then I want to discuss what DeSci is broadly and give an overview of the movement. I want to talk about funding the science commons — the structures we can use to improve the way we fund scientific development, both in the short term and at larger scales. Then I want to give an overview of different efforts across the DeSci landscape and talk about successes so far and promising trajectories for 2023 and 2024. Finally, I want to discuss concrete problems around building better tooling for scientists — tooling around how we access knowledge, manage data, distribute and disseminate data, and make scientific projects much more reproducible so that people can look back to papers five, ten, or twenty years old and reproduce the results.

On almost every single metric of the human experience, over the last few centuries we've seen tremendous progress. The underlying reason for all of this is the Scientific Revolution and the changes put in place after it. Our better ability to understand the universe and build technology to harness the environment around us has led to this accelerating rate of progress. We've also caused all kinds of damage — to ourselves, the environment, and other species — and we need a drastically better handle on things to achieve progress without that damage.

The broader story is that in just a few centuries, humanity has leveled itself up at a scale totally unprecedented in the history of life on this planet. Humanity developing a drastically better way of thinking about problems — generating better explanations for how the universe works — is the fundamental thing enabling us to do what we do.

In a sense, most of our day-to-day attention as a species doesn't go to science, which I think is a mistaken allocation. Our scientific endeavors and our building of technology out of those endeavors should be the top priority for humanity. Our broader allocation doesn't quite match up.

Science tends to be divided into many different fields, but the divisions are much fuzzier than they might have been portrayed. There are tons of areas of science that we have yet to discover, all kinds of physical laws and emerging phenomena we haven't found yet. This is an ever-expanding range of knowledge, and what we need to get really good at is systematizing this area of discovery — this process by which we find things out as an entire species, ideally leveraging all the technology at our disposal.

## The Scientific Method at Scale {7:50}

Everyone knows the scientific method is a cornerstone of the individual approach to science — formulating better explanations and hypotheses, creating testable ways of falsifying those hypotheses, discarding bad ones, and arriving at better structures. From there you share results and get peer review.

But the scientific method is really the individual view. What I think tends to be underappreciated is the larger process — how we systematize and integrate our thinking, how all the individual pieces of science get integrated into a larger-scale model of what humanity knows and what we're able to do. This is the truly valuable enterprise, and it unfortunately tends to be overlooked in terms of building systems to improve it.

There were improvements in the middle of the 20th century when science got systematized and built up at larger scale, and there have been point solutions here and there. But we have yet to see a radical leveling up of how all of science works at that scale. For the most part, we still operate in many fields with the same tools that scientists had in the mid-20th century, even though we now have computers, massive communications networks, and systems that can understand what we write and generate abstractions from it.

The paper is still the main way scientific results get communicated, and humans are left to parse all the assessments plus the implicit knowledge that doesn't get communicated — knowledge that people have to learn by spending time in the field or talking to colleagues.

I'd like to draw attention to improving this larger-scale process. Getting way better at gathering and diffusing data, interpreting data, systematizing conclusions, and tracking different levels of evidence for hypotheses — that's the kind of thing that could accelerate our scientific process by orders of magnitude. This is an extremely high-leverage area where even single-percentage improvements in how individuals or small groups work compound into enormous improvements across the entire species.

DeSci in general is an attempt by many groups around the world that recognize problems across this entire system and are trying to forge a path closer to the startup world — where you can start changing things on your own without writing proposals and getting approval from mainstream institutions. Instead, you can start generating improvements, and if they work better, they might get adopted by the broader market.

Science works extremely well for many things, but today we can point to all kinds of problems. Misallocated funding. Enormous amounts of time going to writing grant proposals. Grant-making systems whose selective ability isn't particularly good — there have been experiments where replacing them with drastically more efficient approaches doesn't perform much worse. We lose data over time as papers age. Software environments rot. Our ability to reproduce and reconfirm results decreases over time. This is a ridiculous problem given that we have computers, version control, and vast data storage. We should have a dramatically higher standard for how we keep our scientific results and data.

## Open Access and Knowledge Distribution {13:54}

Beyond data issues, there's the Open Access movement. We're in a much better place than we were fifteen years ago. Back then, many papers around the world had a bleak future behind paywalls. Today, many laws have been passed that have improved this dramatically, and we can see a pathway toward all kinds of scientific results being forced to be open access.

However, in practice, when you try to find papers, you still hit all kinds of paywalls and friction. We still have a bad, predatory system where parties that are supposed to keep our data, disseminate it well, and highlight it aren't doing that well — and they end up rate-limiting the progress of science through bad data practices and withholding access. This is an area that needs drastic improvement. The good news is we have all of the tools needed to build a better system. It just depends on coordinating social change and building alternative platforms.

## What Is DeSci? {16:04}

DeSci is an approach to address some of these problems with technologies available today. It's not going to solve everything on its own — it's a subset of approaches that starts from organizing systems in a more bottom-up way, as opposed to relying on very large-scale institutions to prescribe how things are done.

What happens when you can coordinate groups of people, institutions, and organizations in more free and open markets? Can you arrive at better funding structures? Better ways of building platforms for keeping and disseminating data? Better environments for making science reproducible?

As I see it, DeSci is a movement to improve science using Web3 technology and tools, with focus areas around open access papers, open access data commons, reproducible experiments, organizing people and labs, creating regenerative funding structures, building better systems for peer review, and producing a much higher quality data science commons.

There are lots of different organizations in this space — the landscape has perhaps doubled in size in terms of organizations in just a few months. There's a ton of activity around how we fund science, how we organize and systematize data, and how we organize people. Many of these groups are having pretty significant success just by providing a social environment and structure for people to carry on their work.

One thing that's very exciting to see is how broadly international this movement is. Having grown up in different places and seen how different institutions work, certain countries just have better infrastructure for doing science. It's been great to see the DeSci movement exporting and diffusing infrastructure to be broadly available to anybody around the internet.

## Funding Structures and the Innovation Chasm {19:54}

I want to talk about funding structures — both the short-term and long-term picture, bounded in the ten to twenty year time scale. There are really massive opportunities here for DeSci.

The way to think about this part of the problem is that there are two different incentive fields when it comes to science and technology. In a sense, science is our ability to draw theories, to understand how the universe works, and then in between you have this massive area of R&D — research and development — where you take scientific results and build them into better tools and technology. Sometimes building a better measurement device is a breakthrough enabler that unlocks all kinds of additional science.

Unfortunately, the economic structure around these environments is disconnected, dealing with two different incentive fields that produce what I call the Innovation Chasm.

On one side, you have the academic credit incentive field. The world has organized academic work to allocate resources and funding based on the likelihood of achieving academic credit as recognized by institutions like journals, conferences, and peer organizations. This yields an environment highly oriented toward "publish or perish," which greatly incentivizes the production of important conceptual results but not necessarily things that are useful downstream. In particular, it doesn't incentivize the vast amounts of work required to translate a conceptual result into something usable for building technology and products.

A concrete example: the academic system incentivizes understanding how optics work, saying something about lenses, and theoretically describing how one might build microscopes or telescopes. But there's very little reward for the vast amount of knowledge that needs to be built around how to actually grind lenses, produce more efficient lenses, scale production, or optimize for different applications. All of that is seen as beneath academic credit and left as an exercise for the implementer.

On the other side, you have the technology production incentive field, oriented by the broader market and larger-scale economic systems. Corporations produce technologies and products and sell them into the market, and their incentive structure yields an environment that is risk-averse and optimized for small investment changes that yield maximum economic benefit. This produces environments that are extremely short-term oriented — think of the massive-scale advertising machine, or the disproportionate investment in entertainment versus fundamental science.

The amount of money in sectors like entertainment or digital goods dwarfs the funding going to science or technology translation. This is one of the key problems: how do we generate better incentive structures to bridge this Innovation Chasm? How do we produce better discoveries while also bridging into technology translation — the extremely expensive, labor-intensive part of R&D?

If you can do really deep technological improvement, those are the kinds of products and technologies that end up being paradigm-shifting and generate massive returns at the scale of hundreds of billions to trillions of dollars — which is what you need to fund a lot more science. You can create a regenerative economic loop where scientific development translates into significant economic returns flowing back into science.

The problem today is that these fields are broken up by systemic structures. Most science is government-funded, and there are limitations in taking conceptual results and turning them into technologies. Government grant programs tend not to invest in the translation area, and venture capital is too far downstream — it starts operating once you have something close to a scalable product. So this chasm has no strong funding from either side.

If we can create a way of linking credit attribution and tracing how conceptual results yield certain technologies that do extremely well in the market over a ten to twenty year scale, we can build a regenerative loop connecting these two areas and build a much stronger way of funding science — especially today, when the fruits of scientific enterprise are being used by corporations generating massive revenue that never flows back to the beginning.

## Worldwide R&D Funding Scale {29:44}

You can look at worldwide R&D funding as fairly large relative to past periods of history, but these scales don't quite match the GDP of the nations investing in them. Just by looking at the actual scales and comparing to similar areas of investment, you can see why certain things aren't progressing that strongly.

The decades where space was in a low-priority mode fall directly out of the R&D funding scale for space. Our progress in energy can be traced back to the level of investment we've put in. When you think about the scale — worldwide science R&D funding is somewhere around two and a half to three trillion dollars — it sounds like a lot, but you can compare it to the revenue of just two or three large tech companies. Global science spending is dwarfed by the revenue of a handful of corporations.

If humanity properly invested in science at the scale that it deserves, say five to ten percent of global GDP, we would probably be generating much faster progress. The macroeconomic structures don't quite line up there, and this is where new funding structures from DeSci could potentially make an extremely large impact.

The amazing thing about the last year and a half is seeing a ton of groups already tackling these kinds of problems, building different grant structures and grant programs. Special highlight to Gitcoin in the DeSci space — many groups are talking about different mechanisms that could be deployed.

## New Funding Mechanisms {34:27}

There are new algorithmic ways of gathering input from many participants in a community to make funding allocation decisions — things like the S-process, N-process, and quadratic funding.

Then there are ways of doing retroactive grant-making. Instead of only funding in advance for work to be done, you flip the equation and do an assessment after success has happened, where it's much easier to tell what actually succeeded. Success can include negative results that generate really good data. This might include retroactive public-good funding structures like impact certificates, impact markets, and hypercerts. These instruments will be extremely useful and successful at larger scales, but we need time and space to generate markets at that scale.

I tend to think of the interest rate as a lever widening or closing this chasm — the lower the interest rates, the tighter the gap; the higher the interest rates, the wider it gets. So expect less funding in high-interest-rate environments, which makes it potentially much more important to have better algorithms for allocation.

Another area where we've perhaps under-invested but which is potentially extremely promising is coming up with new kinds of entities that can do R&D. One notable result is the Focused Research Organization structure that Convergent Research and others have pioneered. These entities are essentially new ways to start a lab, raise funding for it, administer it, and scale it as it proves success — like a startup for scientific research.

If the startup world helped make it way easier to start corporations, how could we create an analogous environment for starting new scientific labs or R&D labs? The ability to innovate in the structure of science itself has a much lower innovation rate compared to the commercial sector. With DAOs and crypto wallets, you already have what you need to organize people with some funding structure and decision-making ability.

## Coordination and Open Source Parallels {38:57}

Even with better funding structures, better reward allocation, and better incentives, we still need better ways of coordinating. I've been disappointed that in the last twenty years, we haven't seen that much success in how to organize large groups of people beyond the traditional structures discovered in the last century and a half.

The open source movement and the emergence of version control and GitHub is an example of building new structures that enable massive-scale coordination at scales previously not well understood. I think we're missing that kind of coordination change in the scientific world. Scientists use things like GitHub and Twitter to diffuse their results, but overall the coordination structure has not been nearly as successful as the software development world with version control, project management tools, and package managers.

What are the analogs of those structures that we could build for scientific enterprises? The DeSci movement is generating a lot of conversation about this. There are lots of talks and discussions about potential mechanisms, and the last year alone has yielded tons of new structures and innovative ideas. I think 2023 is a time to put a lot of these into action — we've spent time deploying a few and generating many ideas; now we need to turn more of those ideas into measurable experiments.

## Better Tooling for Scientists {42:24}

I want to go deeper on some concrete areas where I think we can have short-term successes. The first area is knowledge and making it open access — things like the kind of efforts around peer review tools, new kinds of structures for organizing how knowledge gets assessed and processed.

There are efforts around systematizing peer review and building new kinds of structures. There have already been some successes, though I haven't seen a conference come out that fully uses DeSci-oriented primitives. That might be a great goal for 2023: either work with an existing conference or start a new conference that uses DeSci primitives for the entire process — grabbing papers, doing peer review, publishing, housing papers and artifacts and data. If we create one good end-to-end example, we'll be able to export those results to many other conferences in 2024 and 2025.

One notable result around grants coupling with participation is the Gitcoin-oriented approach, where it's not just resource allocation — you get human participation in the loop, organizing supporters of various projects who come out to work with them directly, lending individual support, guiding where funding goes, and discovering projects they might want to work with. Continuing to scale these efforts will be very successful.

IPFS itself began as an attempt to accelerate science by enabling broad distribution of machine learning datasets. Over the last five to eight years, we've put in a lot of the infrastructure required to move around scientific datasets, papers, and other artifacts through CIDs — content identifiers.

This is being scaled now with the inclusion of CIDs in scientific literature. Papers are starting to include CIDs, which means you can make the publication graph itself interlinked with content identifiers — direct cryptographic identifiers for each paper, artifact, or dataset.

## Data Infrastructure and Reproducibility {47:02}

So one part is being able to move around all the information — providing free and open access to everybody around the world. This is already working pretty well. There are lots of large-scale paper archives moved around with IPFS, and lots of data archives as well.

The next step is getting to reproducible pipelines — being able to describe all the necessary virtual machines and programs to run all the code representing a particular paper, and putting that entire set of artifacts into a single container that you can rerun. Docker was seen as a good potential step, but it isn't sufficient because Docker is not fully reproducible and leaks all kinds of assumptions. Wasm will be a drastically better primitive for this, where we can containerize everything related to a particular paper, isolate network access, grab all the data, and truly make properly reproducible artifacts that you can rerun whenever — five, ten, twenty years from now — without the risk of it rotting and disappearing.

The people working on this have to fight against traditional choices that software development platforms tend to make, and really create an environment optimizing for reproducibility.

## Large-Scale Decentralized Compute {49:10}

Another piece is building computable platforms for larger-scale data science. I think one of the areas 2023 is going to bring is this: we have large-scale incentivized platforms for storage and compute, and now we can start doing large-scale data science over them — data pipelines in the hundreds of petabytes scale, with massive datasets, running computations over them.

This is going to be a huge focus for the IPFS and Filecoin communities. A special plug for the Compute Over Data working group, an open working group bringing together participants from different communities who are building decentralized computation networks, ensuring they're interoperable.

If we do things right, we might generate an environment that can do massive-scale data science experiments and offer a faster, cheaper, more interlinked, and more reproducible alternative for scientists. If we can achieve that, it can spread to the whole world really quickly. Most scientific processing today happens in the cloud because it's more convenient and cheaper. If we can beat that structure and immediately put in hooks to make papers open access and data reproducible, that could be a really great success.

I want to finish with a broader call to action: join up and try to create new funding mechanisms for science, experiment with what's already out there, work on Open Access tooling, work on better data science tooling, work on public datasets, or consider joining one of the DeSci teams or DAOs. If we can make a better future, it'll come down to your participation.

**Host:** Wonderful, thank you so much Juan.

## Q&A Session {52:10}

**Host:** How can traditional science funders like the NSF or NIH participate in DeSci without disrupting existing structures?

**Juan Benet:** This is a really good question. I think the best approach is to start experimenting at the margins. Many of these organizations already have innovation programs or sandboxes where they can try new approaches. The key insight is that DeSci tools don't have to replace existing structures — they can augment them.

For example, a traditional funder could experiment with using quadratic funding for a small allocation of their budget to see how community input compares with expert panel decisions. They could adopt content identifiers for all funded research outputs, which immediately improves discoverability and reproducibility without changing anything else.

The other angle is that these funders can participate in a lot of the grant-making experiments, and the winnings from the DeSci experiments — because they were so well-documented and articulated and the results were so clearly good — many groups have already been able to reproduce them. Get to the spot where you can experiment with your structures and involve a lot of other participants in making those decisions. To the extent that you want to bring in a lot of participants and use things like quadratic funding, it could be great.

Today we're kind of missing good tools for this, so helping develop those tools might go a long way. How do you enable a lot of scientists to participate? If you were to try to enable scientists to participate in, say, an NSF grant program, how would you do it? Would you tell them to get a crypto key and install MetaMask? That seems super hard, but we can build much better tools — just click a link, go to a website, sign in with whatever credentials they already have, and that's it.

**Host:** A question from Shaya — is Protocol Labs doing anything in the life science ecosystem, and how do you address the reproducibility issue?

**Juan Benet:** Great question. We're working across a lot of different areas around funding mechanisms and ways in which people systematize results. We're involved tangentially in life sciences in the same way we're involved in many other groups — by improving funding structures and improving how people gather results.

In life sciences in particular, people move around large-scale datasets, and things like IPFS become extremely useful. The reproducibility challenge gets way harder here. Things like Emerald Cloud Lab are potentially super interesting, although it's not quite there for full life sciences — it's more chemistry and some biochemistry.

The key component is getting to a point where you can describe experiments in a reproducible setting, where as you're describing the thing, you're writing a protocol that should be carried out by other parties who are not you. You want to get the reproducibility articulated in such a way that many independent parties could run the exact same experiment. Ideally you can use CROs or automated cloud lab settings to run those experiments. But this is the furthest away from working compared to purely digital experiments or those closer to physical sciences.

**Host:** One last question from the audience, from Chris — what do you think is the most compelling value proposition that these new Web3 tools could bring to scientists?

**Juan Benet:** The most compelling contribution is in two areas. First, systematizing things better and creating better coordination tools — coordinating data better, and coordinating people and organizations better through funding mechanisms.

Where I think some of this is headed: if crypto networks keep on their pace, growing by a few orders of magnitude — and already some crypto networks are exceeding the capital of some small nations — then these networks could be funding science and R&D at the scale of large nation-states. That's a super interesting potential.

If we see the same kind of growth in the 2020s that we saw in the last ten years, which is not hard to believe when you look at the relative sizes of different asset classes worldwide, cryptocurrency is still tiny compared to most asset classes. Growing by two to four orders of magnitude is actually very realistic.

If we can do that, then crypto networks can start deploying their algorithmic structures to fund R&D properly at the scale of nation-states. If we can build better experimental structures and better systematic structures for how we allocate funding, and then scale the success of crypto networks, we end up with something like a decentralized NSF or a decentralized NIH — funding at that scale. That would be extremely powerful.

**Host:** I totally agree, and this is actually one of the many topics I'm really looking forward to diving into when we record our podcast.

## Closing {1:01:08}

**Host:** Thank you everybody for joining the seminar, and thank you Juan for this amazing and inspiring talk. We invite you to join our next Future of Science Seminar, where Professor Marcus Sherif from the University of Bristol will talk about developing a theory of change for academic science. Thank you all for joining. Thank you, Juan.
