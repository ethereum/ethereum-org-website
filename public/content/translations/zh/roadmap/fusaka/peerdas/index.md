---
title: PeerDAS
description: "了解作为 Fusaka 以太坊协议升级一部分的 PeerDAS"
lang: zh
---

# 点对点数据可用性采样 (PeerDAS) {#peer-das}

自通过 [EIP-4844 引入 blob 交易](/roadmap/danksharding/)以来，以太坊协议正在进行其最重要的扩容升级。 作为 [Fusaka 升级](/roadmap/fusaka/) 的一部分，PeerDAS 引入了一种处理 blob 数据的新方法，为 L2 的\*\*[数据可用性 (DA)](/developers/docs/data-availability/)\*\* 容量带来了大约一个数量级的提升。

[关于 blob 扩容路线图的更多信息](https://blog.ethereum.org/2025/08/22/protocol-update-002)

## 可扩展性 {#scalability}

以太坊的愿景是成为一个中立、安全、去中心化的平台，供全世界所有人使用。 随着网络使用量的增长，需要在网络的可扩展性、安全性和去中心化这三个方面之间取得平衡。 如果以太坊只是在当前设计中增加网络处理的数据量，它将面临压垮 [以太坊赖以实现去中心化的节点](/developers/docs/nodes-and-clients/) 的风险。 可扩展性需要严谨的机制设计，以最大限度地减少权衡。

实现这一目标的策略之一是允许多样化的二层扩容解决方案生态系统，而不是在[一层网络 (L1)](/glossary/#layer-1) 主网上处理所有交易。 [二层网络 (L2)](/glossary/#layer-2) 或 [rollups](/glossary#rollups) 在其各自独立的链上处理交易，并使用以太坊进行验证和保障安全。 仅发布对安全至关重要的承诺并压缩负载，可以让 L2 更高效地利用以太坊的数据可用性 (DA) 容量。 反过来，L1 承载的数据更少，且不影响安全保证，而 L2 则能以更低的燃料费吸引更多用户。 最初，L2 将数据作为普通交易中的 `calldata` 发布，这与 L1 交易争夺燃料，对于批量数据可用性而言不切实际。

## Proto-Danksharding {#proto-danksharding}

L2 扩容的第一个主要步骤是 Dencun 升级，该升级引入了 [Proto-Danksharding](/roadmap/danksharding/) (EIP-4844)。 此次升级为 rollups 创建了一种名为 blob 的新型专用数据类型。 [Blob](/developers/docs/data-availability/blockchain-data-storage-strategies/#eip-4844-blobs)（即二进制大对象）是任意数据的短暂片段，不需要 EVM 执行，节点只存储有限的时间。 这种更高效的处理方式使得 L2 能够向以太坊发布更多数据，并进一步扩容。

尽管使用 blob 对扩容已经大有裨益，但这只是最终目标的一部分。 在当前协议中，网络中的每个节点仍需要下载每个 blob。 瓶颈在于单个节点所需的带宽，随着 blob 数量的增加，需要下载的数据量也直接增加。

以太坊在去中心化方面毫不妥协，而带宽是最敏感的调节因素之一。 即使有能力的人可以广泛使用强大的计算能力，但如果带宽要求不经过仔细调整，即使在发达国家的大城市（如[德国](https://www.speedtest.net/global-index/germany)、[比利时](https://www.speedtest.net/global-index/belgium)、[澳大利亚](https://www.speedtest.net/global-index/australia)或[美国](https://www.speedtest.net/global-index/united-states)），[上传带宽的限制](https://www.speedtest.net/global-index)也可能导致节点只能在数据中心运行。

随着 blob 数量的增加，节点运营商对带宽和磁盘空间的要求也越来越高。 blob 的大小和数量受这些限制。 每个 blob 最多可携带 128kb 的数据，平均每个区块有 6 个 blob。 这只是迈向未来更高效地使用 blob 设计的第一步。

## 数据可用性采样 {#das}

[数据可用性](/developers/docs/data-availability/)是保证所有独立验证链所需的数据对所有网络参与者都可访问。 它确保数据已完全发布，并可用于免信任地验证链的新状态或传入交易。

以太坊 blob 提供了强大的数据可用性保证，确保了 L2 的安全性。 为此，以太坊节点需要完整地下载和存储 blob。 但是，如果我们能在网络中更有效地分发 blob 并避免这一限制呢？

一种不同的数据存储和确保其可用性的方法是**数据可用性采样 (DAS)**。 DAS 引入了去中心化的分工，而不是让运行以太坊的每台计算机都完整存储每个 blob。 它通过将更小、可管理的任务分配到整个节点网络来分担数据处理的负担。 Blob 被分成多个片段，每个节点使用一个在所有节点间均匀随机分布的机制，只下载几个片段。

这带来了一个新问题——证明数据的可用性和完整性。 当单个节点只持有小片段时，网络如何保证数据可用且完全正确？ 一个恶意节点可以提供虚假数据，并轻易破坏强大的数据可用性保证！ 这时密码学就派上用场了。

为确保数据完整性，EIP-4844 已经实现了 KZG 承诺。 这些是在新 blob 添加到网络时创建的密码学证明。 每个区块中都包含一个小证明，节点可以验证收到的 blob 是否与该区块的 KZG 承诺相对应。

DAS 是建立在此基础之上的机制，可确保数据的正确性和可用性。 采样是节点查询一小部分数据并根据承诺进行验证的过程。 KZG 是一种多项式承诺方案，这意味着多项式曲线上的任何一个点都可以被验证。 通过仅检查多项式上的几个点，进行采样的客户端就可以获得数据可用的强概率保证。

## 点对点数据可用性采样 (PeerDAS) {#peer-das}

[PeerDAS (EIP-7594)](https://eips.ethereum.org/EIPS/eip-7594) 是一个在以太坊中实现 DAS 机制的具体提案，这可能是自“合并”以来最大的一次升级。 PeerDAS 旨在扩展 blob 数据，将其分成列并将子集分发给节点。

以太坊借鉴了一些巧妙的数学方法来实现这一点：它将里德-所罗门 (Reed-Solomon) 风格的纠删码应用于 blob 数据。 Blob 数据表示为一个多项式，其系数对数据进行编码，然后通过在额外的点上对该多项式进行求值来创建一个扩展的 blob，从而使求值次数加倍。 这种增加的冗余实现了纠删恢复：即使某些求值丢失，只要包括扩展片段在内的总数据中至少有一半可用，就可以重建原始 blob。

![扩展多项式](./polynomial.png)

实际上，这个多项式有数千个系数。 KZG 承诺是几个字节的值，类似于哈希，所有节点都知道。 每个持有足够数据点的节点都可以[高效地重建完整的 blob 数据集](https://arxiv.org/abs/2207.11079)。

> 趣闻：DVD 也使用了相同的编码技术。 如果你刮花了 DVD，播放器仍然能够读取它，这要归功于里德-所罗门编码，它能补上多项式缺失的部分。

在历史上，区块链中的数据，无论是区块还是 blob，都会广播给所有节点。 通过 PeerDAS 的分割和采样方法，不再需要向所有人广播所有内容。 Fusaka 升级后，共识层网络被组织成 gossip 主题/子网：blob 列被分配给特定的子网，每个节点订阅预定的子集，并且只保管那些片段。

通过 PeerDAS，扩展的 blob 数据被分成 128 个称为“列”的片段。 数据通过专用的 gossip 协议分发给这些节点，这些节点订阅了特定的子网。 网络上的每个常规节点至少参与 8 个随机选择的列子网。 从 128 个子网中的 8 个接收数据意味着此默认节点仅接收所有数据的 1/16，但由于数据已扩展，这相当于原始数据的 1/8。

这使得理论上的扩容极限达到了当前“每个人下载所有内容”模式的 8 倍。 由于节点订阅为 blob 列提供服务的不同随机子网，它们均匀分布的概率非常高，因此每一份数据都存在于网络的某个地方。 运行验证者的节点每运行一个验证者都需要订阅更多的子网。

> 每个节点都有一个唯一的随机生成的 ID，它通常作为其用于连接的公共身份。 在 PeerDAS 中，这个数字用于确定它必须订阅的随机子网集，从而实现所有 blob 数据的均匀随机分布。

一旦节点成功重建原始数据，它就会将恢复的列重新分发回网络，主动修复任何数据缺口并增强整个系统的弹性。 连接到验证者且总余额≥ 4096 ETH 的节点必须是超级节点，因此必须订阅所有数据列子网并保管所有列。 这些超级节点将持续修复数据缺口。 协议的概率性自我修复特性提供了强大的可用性保证，同时不限制只持有部分数据的家庭运营商。

![订阅通过子网分发的列的节点](./subnets.png)

由于上述采样机制，任何只持有 blob 数据一小部分的节点都可以确认数据可用性。 这种可用性是强制性的：验证者必须遵循新的分叉选择规则，这意味着他们只有在验证了数据的可用性后才会接受并投票给区块。

对用户（尤其是 L2 用户）的直接影响是费用降低。 随着 rollup 数据的空间增加 8 倍，用户在其链上的操作费用会随着时间的推移而变得更便宜。 但在 Fusaka 升级后，降低费用需要时间，并取决于 BPO。

## 仅 Blob 参数 (BPOs) {#bpo}

理论上，网络将能够处理多 8 倍的 blob，但增加 blob 是一项需要以逐步方式进行适当测试和安全执行的更改。 测试网为在主网上部署这些功能提供了足够的信心，但在启用更多数量的 blob 之前，我们需要确保点对点 (p2p) 网络的稳定性。

为了在不压垮网络的情况下逐步提高每个区块的目标 blob 数量，Fusaka 引入了\*\*[仅 Blob 参数 (BPO)](https://ethereum-magicians.org/t/blob-parameter-only-bpo-forks/22623)\*\* 分叉。 与需要广泛的生态系统协调、共识和软件更新的常规分叉不同，[BPO (EIP-7892)](https://eips.ethereum.org/EIPS/eip-7892) 是预先编程的升级，可以随时间推移自动增加 blob 的最大数量，无需干预。

这意味着在 Fusaka 激活和 PeerDAS 上线后，blob 的数量将保持不变。 blob 的数量将每隔几周翻一番，直到达到最多 48 个，同时开发者会进行监控，以确保该机制按预期工作，并且不会对运行网络的节点产生不利影响。

## 未来方向 {#future-directions}

PeerDAS 只是[迈向 FullDAS（即 Danksharding）这一更宏大扩容愿景](https://ethresear.ch/t/fulldas-towards-massive-scalability-with-32mb-blocks-and-beyond/19529)的一步。 PeerDAS 对每个 blob 单独使用一维纠删码，而完整的 Danksharding 将在整个 blob 数据矩阵上使用更完整的二维纠删码方案。 在二维上扩展数据可创建更强的冗余属性，并实现更高效的重建和验证。 实现 FullDAS 将需要大量的网络和协议优化，以及额外的研究。

## 扩展阅读{#further-reading}

- [PeerDAS：Francesco D'Amato 讲解的点对点数据可用性采样](https://www.youtube.com/watch?v=WOdpO1tH_Us)
- [以太坊 PeerDAS 文档](https://eprint.iacr.org/2024/1362.pdf)
- [在没有 AGM 的情况下证明 PeerDAS 的安全性](https://eprint.iacr.org/2025/1683)
- [Vitalik 谈 PeerDAS、其影响以及 Fusaka 测试](https://x.com/VitalikButerin/status/1970983281090085200)